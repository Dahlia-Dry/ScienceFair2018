# Challenging Limitations: Using Deep Learning, Time Series Analysis, and Statistical Methods for Noise Reduction to Develop an Innovative Approach to Exoplanet Candidate Detection Using Earth-Based Telescopes
Dahlia Dry, 2018

## Abstract
Currently, the process of identifying exoplanet candidates is conducted almost solely through the use of space telescopes which are capable of surveying only a small, concentrated region of space. Seeking to increase the accessibility of astronomy to others in a way that would heighten the rate at which exoplanet candidates are identified, I attempted to engineer a comprehensive system for the observation and identification of possible new exoplanet candidates in areas not currently being explored by exoplanet missions. The eventual intent of the project is to create a network that any amateur astronomer with modest observational resources can use to share data and access an open source analytical process for exoplanet candidate identification. By making high-quality inferences from astronomical data, this network has the potential to drastically increase the rate at which possible exoplanet candidates can be identified. To address the issues of atmospheric noise and periodic gaps in observation windows that arise when working with data from small aperture earth-based telescopes, a three-tiered approach was adopted to develop the analytical software. First, a convoluted neural net (CNN) system was created to differentiate between transit and non-transit light curves generated using a Gaussian distribution of stellar parameters obtained from analysis of Kepler light curves and translated into arrays of SIFT image descriptor keypoint vectors. Once a classification accuracy of 96% was achieved, periodic 12-hour segments were deleted from the data to simulate daytime periods in which an Earth-based telescope cannot make observations. The gaps were filled through a process that involvs sinusoidal and linear regressions of the data before and after each gap followed by the creation of artificial noise using of approximations of the latent variable distributions and variance at each point in the gap data. The data that was artificially generated to fill in the gaps modeled the actual data that was removed with an accuracy of 83%. In the third stage, noise was artificially added into the Kepler observations to simulate observing conditions on earth, and software was developed to remove that noise through various methods involving the creation of confidence intervals, the use of the durbin-koopman simulation, and Gaussian local level models. The result of this process was an analytics software which classified transit light curves transformed under simulated earth-based observation conditions with 88% accuracy. This software was then applied to observations being made with a 120mm aperture refractor telescope on 28 stars in the region around the constellation Aldebaran, with possible exoplanet identifications pending further data collection.

